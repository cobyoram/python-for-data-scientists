{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised -> DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'heartdisease'\n",
    "\n",
    "# Initialize the postgres engine\n",
    "engine = create_engine(f'postgresql://{postgres_user}:{postgres_pw}@{postgres_host}:{postgres_port}/{postgres_db}')\n",
    "\n",
    "# Read the data from a sql query to the engine\n",
    "heartdisease_df = pd.read_sql('SELECT * from {}'.format(postgres_db), con=engine)\n",
    "\n",
    "# Dispose of the engine\n",
    "engine.dispose()\n",
    "\n",
    "# Define the features and the outcome\n",
    "X = heartdisease_df.iloc[:, :13]\n",
    "y = heartdisease_df.iloc[:, 13]\n",
    "\n",
    "# Replace missing values (marked by ?) with a 0\n",
    "X = X.replace(to_replace='?', value=0)\n",
    "\n",
    "# Binarize y so that 1 means heart disease diagnosis and 0 means no diagnosis\n",
    "y = np.where(y > 0, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Apply DBSCAN to the heart disease data by trying different values for eps and min_samples parameters. You'll realize that it's really hard to get a two cluster solution using DBSCAN if not impossible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "epsilon: 0.2\nminPts: 1\nNumber of clusters: 303\n-------------------------------------------------\nepsilon: 0.2\nminPts: 2\nNumber of clusters: 0\n-------------------------------------------------\nepsilon: 0.2\nminPts: 3\nNumber of clusters: 0\n-------------------------------------------------\nepsilon: 0.2\nminPts: 4\nNumber of clusters: 0\n-------------------------------------------------\nepsilon: 0.5\nminPts: 1\nNumber of clusters: 301\n-------------------------------------------------\nepsilon: 0.5\nminPts: 2\nNumber of clusters: 2\n-------------------------------------------------\nepsilon: 0.5\nminPts: 3\nNumber of clusters: 0\n-------------------------------------------------\nepsilon: 0.5\nminPts: 4\nNumber of clusters: 0\n-------------------------------------------------\nepsilon: 0.7\nminPts: 1\nNumber of clusters: 301\n-------------------------------------------------\nepsilon: 0.7\nminPts: 2\nNumber of clusters: 2\n-------------------------------------------------\nepsilon: 0.7\nminPts: 3\nNumber of clusters: 0\n-------------------------------------------------\nepsilon: 0.7\nminPts: 4\nNumber of clusters: 0\n-------------------------------------------------\nepsilon: 1\nminPts: 1\nNumber of clusters: 294\n-------------------------------------------------\nepsilon: 1\nminPts: 2\nNumber of clusters: 8\n-------------------------------------------------\nepsilon: 1\nminPts: 3\nNumber of clusters: 1\n-------------------------------------------------\nepsilon: 1\nminPts: 4\nNumber of clusters: 0\n-------------------------------------------------\n"
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "eps = [.2, .5, .7, 1]\n",
    "samps = [1, 2, 3, 4]\n",
    "\n",
    "for e in eps:\n",
    "    for s in samps:\n",
    "\n",
    "        dbscan = DBSCAN(eps=e, min_samples=s)\n",
    "        preds = dbscan.fit_predict(X_std)\n",
    "\n",
    "        preds_s = pd.Series(preds)\n",
    "        num_clusts = preds_s.loc[preds_s != -1].nunique()\n",
    "        print('epsilon:', e)\n",
    "        print('minPts:', s)\n",
    "        print('Number of clusters:', num_clusts)\n",
    "        print('-------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solutions that yielded 2 clusters:\n",
    "\n",
    "Epsilon: .5, minPts: 2\n",
    "Epsilon: .7, minPts: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Apply DBSCAN by setting parameters eps=1, min_samples=1, metric=\"euclidean\". Then, increase the value of min_samples. What's the effect of increasing min_samples on the number of clusters DBSCAN identifies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "epsilon: 1\nminPts: 1\nNumber of clusters: 294\nepsilon: 1\nminPts: 2\nNumber of clusters: 8\nepsilon: 1\nminPts: 3\nNumber of clusters: 1\n"
    }
   ],
   "source": [
    "samps = [1, 2, 3]\n",
    "\n",
    "for s in samps:\n",
    "    dbscan = DBSCAN(eps=1, min_samples=s, metric='euclidean')\n",
    "\n",
    "    preds = dbscan.fit_predict(X_std)\n",
    "\n",
    "    preds_s = pd.Series(preds)\n",
    "    num_clusts = preds_s.loc[preds_s != -1].nunique()\n",
    "    print('epsilon:', e)\n",
    "    print('minPts:', s)\n",
    "    print('Number of clusters:', num_clusts)\n",
    "    print('----------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing min_samples decreases the total number of clusters predicted by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Apply DBSCAN by setting parameters eps=1, min_samples=1, metric=\"euclidean\". Then, increase the value of eps. What's the effect of increasing eps on the number of clusters DBSCAN identifies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "epsilon: 1\nminPts: 3\nNumber of clusters: 294\n----------------------------\nepsilon: 2\nminPts: 3\nNumber of clusters: 178\n----------------------------\nepsilon: 3\nminPts: 3\nNumber of clusters: 34\n----------------------------\n"
    }
   ],
   "source": [
    "eps = [1, 2, 3]\n",
    "\n",
    "for e in eps:\n",
    "    dbscan = DBSCAN(eps=e, min_samples=1, metric='euclidean')\n",
    "\n",
    "    preds = dbscan.fit_predict(X_std)\n",
    "\n",
    "    preds_s = pd.Series(preds)\n",
    "    num_clusts = preds_s.loc[preds_s != -1].nunique()\n",
    "    print('epsilon:', e)\n",
    "    print('minPts:', s)\n",
    "    print('Number of clusters:', num_clusts)\n",
    "    print('----------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing epsilon also decreases the number of clusters predicted by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}